# Output directory.
output_dir = "/home/inigosaez/mls/trained_models/density_field_n32_norsd_nmass5_nz1_cnn2"

# File with the values of the cosmological parameters for each simulation.
cosmo_params_file = "/astro/inigosaez/mls/models_parameters/models_parameters_sobol_ndim2.txt"
# Names of the cosmological parameters used for inference.
cosmo_params_names = ["Omega_m", "sigma8"] # Not full support for other parameters yet.

# Fraction of the total dataset to be used.
fraction_total = 1
# Validation and test datasets fractions (applied after fraction_total).
fraction_validation = 0.2
fraction_test = 0.05
# Seed used to split datasets and select fractions.
split_seed = 1234

# Verbose output.
verbose = true
# Number of threads used by pytorch.
n_threads = 1

[train]
# These are the parameters used to train the network.

cnn_type = 2

# Maximum number of epochs.
n_epochs = 1000
# Patience for early stopping.
patience_early_stopping = 70
# Early stopping patience can also be defined as a constant factor with respect to reduce_on_plateau_patience.
# i.e. patience = int(patience_early_stopping_factor x reduce_on_plateau_patience)
# If different from zero, this definition is used.
patience_early_stopping_factor = 1.5

loss_skew = false
loss_kurt = false
gauss_nllloss = false

# Use training parameters from previous tuning run.
# If true, the values of the remaining tranining parameters of this section will not be used.
train_from_tune = true
# Directory with the results of the tuning run. If set to "output_dir" use the same path as output_dir field.
tune_dir = "output_dir"
# Name of the optuna study to be used.
study_name = "mystudy"

# Patience for ReduceOnPlateau learning rate scheduler.
reduce_on_plateau_patience = 10
reduce_on_plateau_factor = 0.1

# Batch size for the training dataset.
batch_size = 32

# Initial learning rate.
learning_rate = 1e-3
# Weight decay for AdamW optimizer.
weight_decay = 0.1

# Dropout rate.
dropout = 0

# If true, use BatchNormalization.
batch_norm = true

# Parameters for the final regression FC block.
regressor_fc_layers = 2
regressor_fc_units_per_layer = 128

# Parameters for the power spectrum FC block.
ps_fc_layers = 2
ps_fc_units_per_layer = 128

# Parameters for the number counts FC block.
nc_fc_layers = 2
nc_fc_units_per_layer = 128

# Parameters for the density_field convolutional block.
density_field_n_channels_base = 1


[probes]
# These parameters control the cosmological probes that are used for inference.

# List of probes to be used.
probe_list = ["density_field"]

[probes.density_field]
# Different mass thresholds and redshifts are combined as different channels.
# The total number of channels is n_mass * n_z, where n_mass is the number of mass thresholds and n_z the
# number of redshifts.

# Root directory with the data. Different mass cuts and redshifts are in sub-directories.
data_dir = "/astro/inigosaez/mls/pinocchio_observables/L1500_N750_sobol_ndim2/density_field_3D_tsc_n32_norsd/"
# List of minimum mass thresholds.
mobs_min = [6e14, 7e14, 8e14, 9e14, 1e15]
mobs_type = "mass"
# List of redshifts (snapshots).
redshift = [0]
# If true, use overdensity maps instead of density maps (i.e. normalize each map individually).
overdensity = false

[probes.power_spectrum]
# Power spectrum from different mass thresholds and redshifts are concatenated into a single 1D array.

# Root directory with the data. Different mass cuts and redshifts are in sub-directories.
data_dir = "/astro/inigosaez/mls/pinocchio_observables/L1500_N750_sobol_ndim2/power_spectrum_TSC_n128_norsd"
# List of minimum mass thresholds.
mobs_min = [1e14]
mobs_type = "mass"
# List of redshifts (snapshots).
redshift = [0]

[probes.number_counts]
# Number counts from different redshifts are concatenated into a single 1D array.

# Root directory with the data. Different redshifts are in sub-directories.
data_dir = "/astro/inigosaez/mls/pinocchio_observables/L1500_N750_sobol_ndim2/number_counts"
# List of mass bins.
mobs_min = [1e14, 5e14, 1e15]
mobs_type = "mass"
# List of redshifts (snapshots).
redshift = [0]
# If true, use cumulative mass bins. If false, use differential mass bins.
cumulative = true

[tune]
# These are the parameters used to tune the hyperparameters of the network.

# Name of the optuna study.
study_name = "mystudy"

# Resume from previous study with same name if it exists.
resume = true
# Delete previous study with same name.
delete_previous = false

# Number of trials per process.
trials = 3
# Maximum number of epochs for each trial.
n_epochs = 1000

# Pruner to be used. Possible values: median, hyperband (see optuna documentation).
pruner = "median"

# Parameters for median pruner (see optuna documentation).
median_n_startup_trials = 5
median_n_warmup_steps = 20
median_n_min_trials = 1

# Parameters for hyperband pruner (see optuna documentation).
hyperband_min_resource = 10
hyperband_reduction_factor = 3

[tune.learning_rate]

low = 1e-4
high = 1e-1
log = true

[tune.weight_decay]

low = 1e-4
high = 1
log = true

[tune.batch_size]

choices = [16, 32, 64, 128]

[tune.regressor_fc_layers]

low = 1
high = 10
step = 1

[tune.regressor_fc_units_per_layer]

low = 50
high = 1000
step = 50

[tune.ps_fc_layers]

low = 1
high = 10
step = 1

[tune.ps_fc_units_per_layer]

low = 50
high = 1000
step = 50

[tune.nc_fc_layers]

low = 1
high = 10
step = 1

[tune.nc_fc_units_per_layer]

low = 50
high = 1000
step = 50

[tune.density_field_n_channels_base]

low = 1
high = 5

[tune.dropout]

low = 0
high = 1

[tune.reduce_on_plateau_patience]

low = 10
high = 50
step = 10

[tune.reduce_on_plateau_factor]

low = 0.01
high = 0.9
log = true

[tune.batch_norm]

choices = [false, true]
